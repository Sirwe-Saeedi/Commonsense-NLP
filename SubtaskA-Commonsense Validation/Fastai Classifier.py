# -*- coding: utf-8 -*-
"""Fastai Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ylPNu2NeWyOG6GGS6L3hkjtfxKO2V4Nd
"""

!nvidia-smi | grep "|   0"

"""#Updating Stuff"""

# Make ready for fast.ai
!curl -s https://course.fast.ai/setup/colab | bash
!pip -q install git+https://github.com/fastai/fastai.git -U

"""#Importing Libraries"""

import fastai
from fastai.text import *
from fastai import *
import pandas as pd
import glob
from numpy import random

"""#Downloading and preparing Traning Data

##Downloading CSV files from task4 repo
"""

subtaskA_URL = 'https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskA_data_all.csv'

subtaskA_Answers_URL = 'https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskA_answers_all.csv'

import urllib.request
urllib.request.urlretrieve(subtaskA_URL , '/content/subtaskA_data_all.csv')

urllib.request.urlretrieve(subtaskA_Answers_URL , '/content/subtaskA_answers_all.csv')

"""##Read subtaskA_data_all.csv
subtaskA_data_all is the released training set of this task
"""

df1 = pd.read_csv(subtaskA_URL , index_col=0)
df1

#df1['Sentences_Seperated'] = df1[['sent0', 'sent1']].apply(lambda x: ' , '.join(x), axis=1)
#df1.drop(['sent0' , 'sent1'], axis=1, inplace=True)
#df1

"""##Read subtaskA_answers_all.csv

The labels are given in a different csv file
"""

df2 = pd.read_csv(subtaskA_Answers_URL , header=None)
df2.columns = ['id', 'answers']
df2.set_index('id', inplace=True)
df2

"""##Dataframe 
The final dataframe/Training set
"""

df = df1.merge(df2 , on='id')
df
#df.shape

"""##If you want to use from_csv"""

#Writing a pandas DataFrame to CSV file
# df.to_csv("training_all.csv")

# df[0:8000]

"""#Seperate training set & test set & validation set

8000 sampels for training data

1000 sampels for validation data

1000 samples for test data
"""

df_training = df[0:8000]
df_valid = df[8000:9000]
df_test = df[9000:10000]
df_test = df_test.drop( 'answers' , axis = 1)
df_training

df_valid

df_test

"""##If you want to use from_csv"""

df_training.to_csv("training-19000.csv")
df_test.to_csv("test-1000.csv")

"""#Tokenizing- ClsDataBunch

Sentences are seperated by a special tokens (mark_fields = true parameter)
"""

data = TextClasDataBunch.from_df('/content', train_df= df_training, valid_df= df_valid, test_df= df_test  , text_cols= [0 , 1], label_cols =[2], mark_fields= True, bs=16)

data.show_batch()

data,  data.classes

#data.vocab.itos[:50]
#data.vocab.stoi
#len(data.vocab.itos)
#t1 = data.train_ds[500][0] 
#t1
#t2 = data.train_ds[500][1]
#t2

"""#Classifier"""

learn_classifier = text_classifier_learner(data , AWD_LSTM, drop_mult=0)

learn_classifier.lr_find()

learn_classifier.recorder.plot()

"""##Training"""

learn_classifier.fit_one_cycle(2, 1e-04, moms=(0.8,0.7))

learn_classifier.save("First")
learn_classifier.load('First');

learn_classifier.recorder.plot_losses()

learn_classifier.model

learn_classifier.unfreeze()
learn_classifier.summary()

for index, layer in enumerate(learn_classifier.layer_groups):
  print('Layer Group Index: ', index, layer)

def summary_trainable(learner):
  result = []
  total_params_element = 0
  def check_trainable(module):
    nonlocal total_params_element
    if len(list(module.children())) == 0:
      num_param = 0
      num_trainable_param = 0
      num_param_numel = 0
      for parameter in module.parameters():
        num_param += 1
        if parameter.requires_grad:
          num_param_numel += parameter.numel()
          total_params_element += parameter.numel()
          num_trainable_param += 1

      result.append({'module': module, 'num_param': num_param , 'num_trainable_param' : num_trainable_param, 'num_param_numel': num_param_numel})
  learner.model.apply(check_trainable)
  
  print("{: <85} {: <17} {:,<20} {: <40}".format('Module Name', 'Total Parameters', 'Trainable Parameters', '# Elements in Trainable Parametrs'))
  for row in result:
    print("{: <85} {: <17} {: <20} {: <40,}".format(row['module'].__str__(), row['num_param'], row['num_trainable_param'], row['num_param_numel']))
  print('Total number of parameters elements {:,}'.format(total_params_element))

learn_classifier.freeze()
summary_trainable(learn_classifier)

learn_classifier.freeze()
learn_classifier.freeze_to(-1)
summary_trainable(learn_classifier)

learn_classifier.freeze()
learn_classifier.freeze_to(-2)
summary_trainable(learn_classifier)

learn_classifier.freeze()
learn_classifier.freeze_to(-3)
summary_trainable(learn_classifier)

learn_classifier.freeze()
learn_classifier.freeze_to(-4)
summary_trainable(learn_classifier)

learn_classifier.freeze()
learn_classifier.freeze_to(-5) # equal to unfreeze
summary_trainable(learn_classifier)

learn_classifier.freeze()
learn_classifier.unfreeze()
summary_trainable(learn_classifier)